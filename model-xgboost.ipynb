{"cells":[{"metadata":{"_uuid":"6eb071bde88ed08cb1074b68ec11f1fdb8be3e9d","collapsed":true,"_cell_guid":"b4d0b03a-adea-4e73-ab2b-a97667efb4a7"},"cell_type":"markdown","source":"**N.B**\nDue to the time limit on notebook, I choose 320,000 samples to save time.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport gc #exposes the underlying memory management mechanism of Python, the automatic garbage collector. \n            #The module includes functions for controlling how the collector operates and to examine the objects known to the system, \n            #either pending collection or stuck in reference cycles and unable to be freed.\nimport re\nfrom matplotlib import pyplot as plt\nimport xgboost as xgb\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.optimizers import RMSprop\n\nfrom sklearn.model_selection import train_test_split\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmax_num_features = 10\npad_size = 1\nboundary_letter = -1\nspace_letter = 0\n\n\ndf = pd.read_csv('/kaggle/input/en_train.csv.zip')\n\nx_data = []\ny_data =  pd.factorize(df['class'])#Encode the object as an enumerated type or categorical variable.\n                                    #This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct values.\n\n    \nlabels = y_data[1]\ny_data = y_data[0]\ngc.collect()#Although the garbage collector runs automatically as the interpreter executes your program, \n            #you may want to trigger collection to run at a specific time when you know there are a lot of objects to free \n            #or there is not much work happening in your application. Trigger collection using collect().\nfor x in df['before'].values:\n    x_row = np.ones(max_num_features, dtype=int) * space_letter\n    for xi, i in zip(list(str(x)), np.arange(max_num_features)):\n        x_row[i] = ord(xi)\n    x_data.append(x_row)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_data_size = 320000","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"507c9117084d895edf7823bc21e512a299000220","_cell_guid":"996fd5b5-2565-4d26-a7c2-49935e2a908e","trusted":true},"cell_type":"code","source":"\ndef context_window_transform(data, pad_size):\n    pre = np.zeros(max_num_features)\n    pre = [pre for x in np.arange(pad_size)]\n    data = pre + data + pre\n    neo_data = []\n    for i in np.arange(len(data) - pad_size * 2):\n        row = []\n        for x in data[i : i + pad_size * 2 + 1]:\n            row.append([boundary_letter])\n            row.append(x)\n        row.append([boundary_letter])\n        neo_data.append([int(x) for y in row for x in y])\n    return neo_data\n\nx_data = x_data[:max_data_size]\ny_data = y_data[:max_data_size]\nx_data = np.array(context_window_transform(x_data, pad_size))\ngc.collect()\nx_data = np.array(x_data)\ny_data = np.array(y_data)\n\nprint('Total number of samples:', len(x_data))\nprint('Use: ', max_data_size)\n#x_data = np.array(x_data)\n#y_data = np.array(y_data)\n\nprint('x_data sample:')\nprint(x_data[0])\nprint('y_data sample:')\nprint(y_data[0])\nprint('labels:')\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_data\ny_train = y_data\ngc.collect()\n\nx_train, x_valid, y_train, y_valid= train_test_split(x_train, y_train,\n                                                      test_size=0.1, random_state=2017)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3565df1fd23bbd6d11adee7660c6837318d4a07d","_cell_guid":"ecef095f-4641-4dd3-8d07-71eaed4bd95f","trusted":true},"cell_type":"code","source":"\nnum_class = len(labels)\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndvalid = xgb.DMatrix(x_valid, label=y_valid)\nwatchlist = [(dvalid, 'valid'), (dtrain, 'train')]\n\nparam = {'objective':'multi:softmax',\n         'eta':'0.3', 'max_depth':10,\n         'silent':1, 'nthread':-1,\n         'num_class':num_class,\n         'eval_metric':'merror'}\nmodel = xgb.train(param, dtrain, 50, watchlist, early_stopping_rounds=20,\n                  verbose_eval=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\n\npred = model.predict(dvalid)\npred = [labels[int(x)] for x in pred]\ny_valid = [labels[x] for x in y_valid]\nx_valid = [ [ chr(x) for x in y[2 + max_num_features: 2 + max_num_features * 2]] for y in x_valid]\nx_valid = [''.join(x) for x in x_valid]\nx_valid = [re.sub('a+$', '', x) for x in x_valid]\n\ngc.collect()\n\ndf_pred = pd.DataFrame(columns=['data', 'predict', 'target'])\ndf_pred['data'] = x_valid\ndf_pred['predict'] = pred\ndf_pred['target'] = y_valid\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred.to_csv(os.path.join(r'.', 'pred.csv'))\n\ndf_erros = df_pred.loc[df_pred['predict'] != df_pred['target']]\ndf_erros.to_csv(os.path.join(r'.', 'errors.csv'), index=False)\n\nmodel.save_model(os.path.join(r'.', 'xgb_model'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}